\section{Discussion}

The primary aim of this study is to investigate how gaze-based strategies vary for tasks, tool familiarity, and manual planning in naturalistic settings. With our study, we successfully added to the current body of research in two important ways. Firstly, irrespective of the realism of the action affordance in virtual environments, the number, and location of anticipatory fixations were modulated by goal-oriented factors of task and tool familiarity. Secondly, anticipatory fixations related to proximal manual planning were only seen when the setup allowed for more realistic action affordances with the virtual hand mimicking finer hand and finger movements. In sum, proximal and distal goal-oriented planning is highly contextualized to the realism of action/interaction afforded by the environment.


We conducted two experiments to disentangle the role of action affordance for goal-oriented planning. Participants interacted with 3D tool models using VR controllers in a low realism setup, which produced a virtual grasp by pulling their index fingers. Here, we showed that the odds of sampling visual information from the mechanical properties of a tool are different based on the specificity of the task. Moreover, given tool familiarity, the odds of fixating on the effector increased for unfamiliar tools. Tool-specific knowledge also played a major role when subjects were instructed to produce tool-specific movements. Moreover, the spatial orientation of the tool did not affect the odds of fixations for the tool effector. In sum, with the preparation of a symbolic grasping action, fixations were affected by distal goal-oriented factors of task and tool familiarity. 

In a high realism setup, participants interacted with tool models by producing an actual grasp over the tools. The results were similar to the first experiment. However, we additionally found a significant effect of spatial orientation of the tool where the odds of fixations in favor of the tool effector decreased when the tool was presented incongruent to the subjects’ handedness. These results suggest that fixations are directed towards the handle of the tool in anticipation of planning the proximal goal of an optimal grasp. Interestingly, the optimal grasp planning is initiated from the beginning until the end of the viewing time window and might be more critical than inspecting the tool effector to produce the correct action. Taken together, the preparation of a realistic grasping action modulated anticipatory fixations related to both proximal and distal goal planning.


These results are in line with the findings reported by \citet{Belardinelli2016-xb}. They investigated behavioral responses to task and tool-based affordances in a lab where subjects responded to stimuli images on a computer screen and pantomimed their manual actions. Moreover, they presented the tools with the handle always oriented on the right and congruent to the subject’s handedness. Our results suggest that well before action initiation, subjects had to substantially plan their hand movement on the tool to interact with it. This effect is indicative of an end-state comfort planning \citep{Herbort2012-ma} where both proximal and distal goal-oriented planning interacts to modulate anticipatory fixations. From the perspective of ecological validity, our findings give a fuller view of how different planning strategies are needed to produce relevant action. Our study shows that within a naturalistic setting, task, tool familiarity, and the spatial orientation of the tool affect the planning and production of relevant actions. Hence, our study offers a veridical and ecological valid context to aspects of anticipatory behavior control.

Studies in eye-hand coordination \citep{Johansson2001-sa, Lohmann2019-fy, Belardinelli2018-xm} have shown that eye movements are predictively made towards the grasp contact points. Furthermore, \citet{Flanagan2006-ql} proposed that predictions are made in an event-oriented manner and are at the heart of successful control strategies for object manipulations. They posit that predicted sensory events are compared with actual events like grasping, lifting, moving the object to monitor task progression. In contrast, \citet{Iacoboni2005-kw} and \citet{Wohlschlager2003-qe} showed that goal-oriented planning is specified at an abstract level rather than at the movement level. Our results suggest that the anticipatory gaze behavior specific to task and tool familiarity is seen only when additional grasp control planning is not needed. Inversely, optimal motor control might supersede planning based on other distal goals. Here, we make the case that predictions are made for action outcomes at various scales, and that eye movements are used to plan both optimal grasp control and task-specific requirements well before action initiation. 


Our study adds to the growing body of evidence that anticipation and prediction are at the core of cognition \citep{Pezzulo2007-ot}. Motor theories of cognition have proposed that simulations of actions reuse  internal models of motor commands to effect multiple predictions \citep{Jeannerod2006-dt}. The simulation of action theory has been used to explain numerous phenomena of planning, prediction of external events, visual perception, and imitation. \citet{Hoffmann2003-ur} introduced anticipatory behavior control as the mechanism by which action-effect representations are activated by the need for an effect-related goal and contingent stimuli. Furthermore, \citet{Pezzulo2021-te} recently proposed that generative models provide top-down predictive signals for perception, cognition, and action during active tasks and these signals are otherwise weak and/or absent when the brain is at rest or the stimuli are weak. Our study shows that anticipatory behavior is tightly linked to the production of task-relevant actions and contextualized to the realism of the action affordance.

Notably, our study shows that different constraints on the method of interaction can also result in different anticipatory behavioral responses. From the perspective of \citet{Gibson1977-zj}, the affordances of the environment are tightly linked to the actions that one can perform in it. Similarly, \citet{ORegan2001-pd} posited that actions constitute the cognitive processes that govern relevant sensorimotor contingencies. In our study, the production of relevant actions significantly modulated the visual sampling of the tool parts in accordance to goal-oriented factors such as task and tool familiarity irrespective of the action affordance. Taken together, our study shows that some aspects of anticipatory gaze are dependent on the realism of the action afforded by the environment.

We conducted the present study in virtual reality, which is still a burgeoning technology for vision research. While VR environments pose an exciting avenue of research, there are still limitations that practitioners must face while conducting experiments in these scenarios. First, the naturalistic setting of both experiments I and II afforded natural head movements. To maintain optimal quality over the data, we asked the participants in the study to make limited head movements. Additionally, we presented the tools and the task cues not to cause extreme pitch head movements. Secondly, mobile eye-trackers can be error-prone and might suffer from variable sampling rates \citep{Ehinger2019-xr} or calibration errors due to slippage \citep{Niehorster2020-yq}. To mitigate any calibration errors, we also made sure that we calibrated the eye-trackers at regular intervals. Thirdly, both controller-based and camera-based VR interaction methods are still new technology. It could have been challenging for participants to get used to, even though we made sure they practiced the interaction method before the experiment. While we simulated grasping the tool using LeapMotion’s gesture recognition and were able to produce a more realistic action affordance through mimicking finer hand and finger movements, it is still an inadequate substitute for a real grasp where the tactile feedback of the tool in hand might elicit more accurate responses. For example,\citet{Ozana2018-ih} showed that grasping movements within a virtual environment differ both quantitatively and qualitatively from typical grasping. Lastly, there are obvious differences in the realism of the two virtual environments used in the study in terms of the visual scene. While there are visible differences between the environments, we see that there are no significant differences between the percentage of fixations allocated to the background vs. tool for both experimental settings. Hence, we contend that the differences in the eye movement behavior reported in the study are largely a consequence of the differences in the action affordance and much less because of mere visual differences. In light of these limitations, we know that our study must be considered from a nuanced perspective. Furthermore, there is still room for replicating our study with novel and more realistic interaction methods.

There are still some open questions pertaining to anticipatory behavior elicited by tool interactions. Firstly, while our study distinguishes between levels of action affordances, future work can look at goal-oriented planning for passive observers at both proximal and distal levels. Secondly, it would be interesting to dive deeper into the predictive brain signals that give rise to the present oculomotor behaviors. Our study provides a first step towards distinctly investigating proximal and distal goal-oriented planning.

\section{Conclusion}

The present study gives a veridical and ecologically valid context to planning and anticipatory behavior. Our results support the hypothesis that eye movements serve the cognitive function of actively sampling information from the environment to produce relevant actions. When semantic information about the object is not readily available, eye movements are used to seek information from its mechanical properties from specific locations. Furthermore, we show that fixations are made in a goal-oriented way in anticipation of the relevant action. When considering the realism of the action affordance, our results show that eye movements prioritize proximal goals of optimal grasp over task-based demands. Lastly, our study is at the frontiers of naturalistic vision research, where novel technologies can be harnessed to answer questions that were previously far-fetched.


